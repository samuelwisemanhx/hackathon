# AI Fluency Assessment: Evidence-Based Self-Evaluation

## Purpose

This assessment evaluates your AI fluency across five competencies using demonstrated capability rather than self-rating. Complete all sections honestly, then use the companion **Evaluation Prompt** to receive scored results and a personalized 90-day improvement roadmap.

**Time Required**: 25-35 minutes (complete in one sitting for best results)

**Critical**: Your responses will be evaluated against explicit rubrics. Provide concrete examples and honest descriptions of your actual practices—not what you think sounds impressive.

---

## Assessment Structure

You'll complete six parts that generate evidence across five scored competencies:

**Scored Components:**

1. **Prompt Mastery** (40% weight) - Your ability to construct effective, structured prompts
2. **Technical Understanding** (15% weight) - Your knowledge of how AI systems work and their limitations
3. **Practical Application** (20% weight) - How systematically you've integrated AI into real workflows
4. **Critical Evaluation** (15% weight) - Your validation and verification practices
5. **Workflow Design** (10% weight) - Your ability to create repeatable, documented processes

**Plus**: Learning Velocity assessment (informs roadmap, not scored separately)

---

## How This Works

1. **Complete all six parts below** - Be specific and honest
2. **Copy your completed assessment** including all your responses
3. **Use the Evaluation Prompt** - Paste your responses there for scoring and roadmap
4. **Receive**: Component scores, overall rating, competitive context, and 90-day improvement plan

---

## PART 1: CORE SKILL TESTS

### TEST 1 - SPECIFICITY CHALLENGE

Transform this generic prompt into something you'd actually use for real work.

**Generic starting prompt:**

`"Help me write a proposal for a potential client."`

**Your improved version:**

`[PASTE YOUR IMPROVED PROMPT HERE - the actual prompt you would send to an AI tool, not what you think sounds good. Show your real working approach.]`

**Context checklist** - Did your improved prompt specify:

- [ ] Client characteristics (industry, size, decision-making style)
- [ ] Proposal type (service agreement, partnership, project bid)
- [ ] Desired outcome (meeting, signature, pilot program, next steps)
- [ ] Constraints (length, tone, timeline, approval requirements)
- [ ] Success criteria (what makes this proposal effective)
- [ ] Output format (structure, sections, level of detail)

---

### TEST 2 - ITERATION TEST

**Scenario**: You've received AI-generated content that's 70% right but needs improvement. You can only improve it through better prompting—no manual editing.

**Task**: Describe your actual iteration process.

**Number of revision attempts you typically use**: ___

**Your iteration approach** (be specific about what you actually do):

**Iteration 1:**

`What specific improvement do you request first? Write the actual follow-up prompt or describe your approach: [YOUR FIRST ITERATION FOCUS]`

**Iteration 2:**

`What do you focus on in the second round? What prompt or approach do you use? [YOUR SECOND ITERATION FOCUS]`

**Iteration 3 (if applicable):**

`[YOUR THIRD ITERATION FOCUS - or write "I usually stop at 2 iterations"]`

**How you know you're done:**

`[What criteria tell you the output is good enough to use?]`

---

### TEST 3 - WORKFLOW TEST

**Task you use AI for regularly:**

`[DESCRIBE ONE SPECIFIC TASK you do often where you use AI - be concrete about what the task is, not just "writing" or "research"]`

**Your current process** (describe what you actually do, step-by-step):

**Step 1 - Preparation:**

`[What do you do before writing your first prompt? Any context gathering, documentation review, or setup?]`

**Step 2 - Initial Prompt:**

`[Describe your typical first prompt approach for this task. How much detail? What structure? Do you use any frameworks?]`

**Step 3 - Iteration:**

`[How do you refine the output? What's your process for getting from first draft to usable result?]`

**Step 4 - Quality Check:**

`[How do you validate the output? What do you check? How do you know it's good enough?]`

**Step 5 - Integration:**

`[What happens to the output? How does it get used? Any final modifications?]`

**Tools used for this workflow:**

`[Which AI tool(s)? Any other tools in the process?]`

---

## PART 2: TECHNICAL UNDERSTANDING

Answer these questions to reveal your knowledge of how AI systems work:

**Q1: Tool Selection**

`Which AI tools do you use regularly? Why did you choose them over alternatives? (Be specific about what drives your tool selection decisions.)

[YOUR ANSWER]`

**Q2: Failure Diagnosis**

`Can you explain why a prompt might fail and how you'd fix it? If possible, give a specific example from your experience.

[YOUR ANSWER]`

**Q3: Context Windows**

`What do you understand about context windows and why they matter? Complete this: "I understand context windows well enough to..."

[YOUR ANSWER]`

**Q4: Task Suitability**

`When should you use AI for a task vs. not use it? What characteristics make a task suitable or unsuitable for AI assistance?

[YOUR ANSWER]`

**Q5: Model Differences (Optional)**

`If you've used multiple AI models (GPT-4, Claude, Gemini, etc.), what meaningful differences have you noticed? What makes you choose one over another for specific tasks?

[YOUR ANSWER - or write "I primarily use one tool"]`

---

## PART 3: CRITICAL EVALUATION

Answer these to reveal your validation and verification practices:

**Q1: Professional Verification Checklist**

`What do you ALWAYS check in AI output before using it professionally? List your actual verification steps in order.

[YOUR ANSWER - be honest about what you actually verify, not what you think you should verify]`

**Q2: Error Detection Experience**

`Describe a specific time AI gave you wrong information. How did you catch it? What did you learn from that experience?

[YOUR ANSWER - or write "This hasn't happened to me yet" if true]`

**Q3: Factual Validation Process**

`What's your process for validating factual claims in AI output? Be specific about the steps you take.

[YOUR ANSWER]`

**Q4: Uncertainty Handling**

`How do you handle situations where you're not sure if AI output is accurate? Walk through your decision process.

[YOUR ANSWER]`

**Q5: Known Failure Modes**

`What are you most careful about when using AI? What types of errors or issues do you actively watch for?

[YOUR ANSWER]`

---

## PART 4: PRACTICAL APPLICATION

Provide concrete data about your real-world integration:

**Q1: Usage Volume**

`How many hours per week do you actively use AI tools?

[YOUR ANSWER: ___ hours/week]`

**Q2: Time Savings Documentation**

`List 3-5 specific tasks where AI reliably saves you time. Be concrete and quantify when possible:

Task 1: [Specific task description] - Saves approximately [X] hours/week 
Task 2: [Specific task description] - Saves approximately [X] hours/week  
Task 3: [Specific task description] - Saves approximately [X] hours/week 
Task 4: [Optional] 
Task 5: [Optional]`

**Q3: Workflow Documentation**

`Do you have documented workflows for your AI processes?

- If YES: For which tasks? Where are they documented? (personal notes, shared docs, team wikis?)
- If NO: Why not? What prevents you from documenting them?

[YOUR ANSWER]`

**Q4: Knowledge Transfer**

`Have you taught anyone else your AI processes or workflows? What was the result? If not, why not?

[YOUR ANSWER]`

**Q5: Tool Selection Framework**

`How do you decide which AI tool to use for a given task? Walk through your decision process.

[YOUR ANSWER]`

**Q6: Integration Barriers**

`What prevents you from using AI more extensively in your work? What tasks have you tried AI on that didn't work well?

[YOUR ANSWER]`

---

## PART 5: VELOCITY SELF-ASSESSMENT

These questions help assess how quickly you're learning and adapting:

**Q1: Experience Timeline**

`How long have you been using AI tools at approximately your current level of sophistication?

[YOUR ANSWER: timeframe and brief description]`

**Q2: Recent Learning**

`When did you last learn a new AI technique or capability? What specifically did you learn? When was this?

[YOUR ANSWER with specific timeframe]`

**Q3: Meta-Learning**

`Do you use AI to learn about AI capabilities and techniques?

- If YES: Give a specific example of how you've done this
- If NO: Why not?

[YOUR ANSWER]`

**Q4: Skill Acquisition Speed**

Select the option that best describes how quickly you typically master a new prompting pattern or technique:

- [ ] **Days** - I experiment, document, and integrate new techniques quickly into my workflows
- [ ] **Weeks** - I eventually master new techniques with consistent practice
- [ ] **Months** - It takes me significant time to internalize new patterns
- [ ] **Stable** - I don't track this / I generally stick with what I know and works

**Q5: Evolution Pattern**

`Describe how your AI usage has evolved over the past 3-6 months. What's different about how you use AI now compared to 3-6 months ago? Be specific about what changed.

[YOUR ANSWER]`

**Q6: Learning Approach**

`How do you learn new AI capabilities or techniques? (Online courses, documentation, experimentation, community, etc.)

[YOUR ANSWER]`

---

## PART 6: TOOLS & TECHNIQUES (Optional)

This helps the evaluation account for advanced or uncommon approaches:

**Advanced Tools or Techniques:**

`List any specific AI tools, frameworks, or techniques you currently use that might be uncommon or recently developed:

- Custom instructions / system prompts
- API usage / programmatic access
- Multi-tool workflows
- Retrieval systems (RAG)
- Agent frameworks
- Custom GPTs or Claude Projects
- Other advanced techniques

[YOUR ANSWER - or write "Standard tools only (ChatGPT, Claude, etc.)" if you're using mainstream chat interfaces]`

**Prompting Frameworks:**

`Do you use any specific prompting frameworks or methodologies? (Examples: RICE, COSTAR, Chain-of-Thought, Tree-of-Thought, etc.)

[YOUR ANSWER - or write "No specific frameworks"]`

---

## COMPLETION

You've finished the assessment!

**Next Steps:**

1. **Review your responses** - Make sure you've answered honestly and specifically
2. **Copy everything** - From "PART 1: CORE SKILL TESTS" through "PART 6: TOOLS & TECHNIQUES"
3. **Use the Evaluation Prompt** - Paste your responses there to receive:
    - Component scores (1-10) with detailed justification
    - Overall weighted score and competitive context
    - Learning velocity assessment
    - 90-day personalized improvement roadmap
    - Immediate action items

---

## Critical Reminders

**For accurate evaluation:**

- ✓ Be specific about what you actually do, not what you think you should do
- ✓ Provide concrete examples wherever possible
- ✓ Quantify when you can (time saved, hours used, number of iterations)
- ✓ Admit gaps honestly - "I don't do this" is better than vague aspiration
- ✓ If you haven't documented workflows, say so - don't claim documentation that doesn't exist

**Your evaluation quality depends on response quality:**

- Vague answers → Lower scores
- Specific examples → Accurate assessment
- Honest gaps → Actionable roadmap
- Inflated claims → Misaligned improvement plan

---

## Scoring Preview

Your responses will be evaluated against these rubric levels:

**Levels 1-2**: Basic or inconsistent use

**Levels 3-4**: Regular use with some structure

**Levels 5-6**: Systematic approach with consistent practices

**Levels 7-8**: Advanced integration with documented processes

**Levels 9-10**: Expert-level with teaching/building capabilities

Each component has detailed criteria. The evaluation prompt will show exactly where your evidence places you on each scale.

---

**Ready?** Complete all six parts above, then proceed to the Evaluation Prompt with your responses.